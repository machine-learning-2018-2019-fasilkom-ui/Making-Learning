{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\"https://towardsdatascience.com/build-your-own-convolution-neural-network-in-5-mins-4217c2cf964f\", \"https://arxiv.org/pdf/1409.1556.pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_EXP(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=(H,W,1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='softmax'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='Adagrad',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_VGG(num_classes):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAFFE utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root = 'dataset/jaffe/'\n",
    "image_title = os.listdir(image_root)\n",
    "image_dirs = [image_root + x for x in os.listdir(image_root)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AffectNet utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\KULIAH\\DSA\\TA\\Manually_Annotated\n"
     ]
    }
   ],
   "source": [
    "cd D:\\Documents\\KULIAH\\DSA\\TA\\Manually_Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv = pd.read_csv('training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(0: Neutral, 1: Happy, 2: Sad, 3:\n",
    "Surprise, 4: Fear, 5: Disgust, 6: Anger, 7: Contempt, 8: None, 9:\n",
    "Uncertain, 10: No-Face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_csv = pd.read_csv('validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root = 'Manually_Annotated_Images\\\\'\n",
    "image_dirs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subDirectory_filePath</th>\n",
       "      <th>face_x</th>\n",
       "      <th>face_y</th>\n",
       "      <th>face_width</th>\n",
       "      <th>face_height</th>\n",
       "      <th>facial_landmarks</th>\n",
       "      <th>expression</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>689/737db2483489148d783ef278f43f486c0a97e140fc...</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "      <td>899</td>\n",
       "      <td>899</td>\n",
       "      <td>181.64;530.91;188.32;627.82;195.1;723.37;205.2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>-0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392/c4db2f9b7e4b422d14b6e038f0cdc3ecee239b5532...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>137</td>\n",
       "      <td>137</td>\n",
       "      <td>28.82;77.52;29.12;93.25;31.04;108.51;33.03;123...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.017253</td>\n",
       "      <td>0.004313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>468/21772b68dc8c2a11678c8739eca33adb6ccc658600...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>176</td>\n",
       "      <td>176</td>\n",
       "      <td>30.52;87.33;32.55;106.43;36.94;125.81;43.06;14...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>944/06e9ae8d3b240eb68fa60534783eacafce2def60a8...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>269</td>\n",
       "      <td>269</td>\n",
       "      <td>44.43;158.17;47.08;189.2;50.54;221.88;58.3;253...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.153401</td>\n",
       "      <td>0.038890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>993/02e06ee5521958b4042dd73abb444220609d96f57b...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td>50.59;78.72;48.6;93.23;48.72;109.06;48.8;123.0...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.783972</td>\n",
       "      <td>-0.551684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               subDirectory_filePath  face_x  face_y  \\\n",
       "0  689/737db2483489148d783ef278f43f486c0a97e140fc...     134     134   \n",
       "1  392/c4db2f9b7e4b422d14b6e038f0cdc3ecee239b5532...      20      20   \n",
       "2  468/21772b68dc8c2a11678c8739eca33adb6ccc658600...      11      11   \n",
       "3  944/06e9ae8d3b240eb68fa60534783eacafce2def60a8...      40      40   \n",
       "4  993/02e06ee5521958b4042dd73abb444220609d96f57b...      22      22   \n",
       "\n",
       "   face_width  face_height                                   facial_landmarks  \\\n",
       "0         899          899  181.64;530.91;188.32;627.82;195.1;723.37;205.2...   \n",
       "1         137          137  28.82;77.52;29.12;93.25;31.04;108.51;33.03;123...   \n",
       "2         176          176  30.52;87.33;32.55;106.43;36.94;125.81;43.06;14...   \n",
       "3         269          269  44.43;158.17;47.08;189.2;50.54;221.88;58.3;253...   \n",
       "4         153          153  50.59;78.72;48.6;93.23;48.72;109.06;48.8;123.0...   \n",
       "\n",
       "   expression   valence   arousal  \n",
       "0           1  0.785714 -0.055556  \n",
       "1           0 -0.017253  0.004313  \n",
       "2           0  0.174603  0.007937  \n",
       "3           1  0.153401  0.038890  \n",
       "4           8  0.783972 -0.551684  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dirs = []\n",
    "for i in range(size):\n",
    "    path = image_root + training_csv['subDirectory_filePath'][i].replace('/','\\\\')\n",
    "    image_dirs.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 128\n",
    "W = 128\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    dimension = (H,W)\n",
    "    resized = cv2.resize(img, dimension)\n",
    "    return resized\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, 1, H, W), dtype=np.uint8)\n",
    "    for i, image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image\n",
    "        if i%50 == 0: print('Processed {} of {}'.format(i, count))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 10000\n",
      "Processed 50 of 10000\n",
      "Processed 100 of 10000\n",
      "Processed 150 of 10000\n",
      "Processed 200 of 10000\n",
      "Processed 250 of 10000\n",
      "Processed 300 of 10000\n",
      "Processed 350 of 10000\n",
      "Processed 400 of 10000\n",
      "Processed 450 of 10000\n",
      "Processed 500 of 10000\n",
      "Processed 550 of 10000\n",
      "Processed 600 of 10000\n",
      "Processed 650 of 10000\n",
      "Processed 700 of 10000\n",
      "Processed 750 of 10000\n",
      "Processed 800 of 10000\n",
      "Processed 850 of 10000\n",
      "Processed 900 of 10000\n",
      "Processed 950 of 10000\n",
      "Processed 1000 of 10000\n",
      "Processed 1050 of 10000\n",
      "Processed 1100 of 10000\n",
      "Processed 1150 of 10000\n",
      "Processed 1200 of 10000\n",
      "Processed 1250 of 10000\n",
      "Processed 1300 of 10000\n",
      "Processed 1350 of 10000\n",
      "Processed 1400 of 10000\n",
      "Processed 1450 of 10000\n",
      "Processed 1500 of 10000\n",
      "Processed 1550 of 10000\n",
      "Processed 1600 of 10000\n",
      "Processed 1650 of 10000\n",
      "Processed 1700 of 10000\n",
      "Processed 1750 of 10000\n",
      "Processed 1800 of 10000\n",
      "Processed 1850 of 10000\n",
      "Processed 1900 of 10000\n",
      "Processed 1950 of 10000\n",
      "Processed 2000 of 10000\n",
      "Processed 2050 of 10000\n",
      "Processed 2100 of 10000\n",
      "Processed 2150 of 10000\n",
      "Processed 2200 of 10000\n",
      "Processed 2250 of 10000\n",
      "Processed 2300 of 10000\n",
      "Processed 2350 of 10000\n",
      "Processed 2400 of 10000\n",
      "Processed 2450 of 10000\n",
      "Processed 2500 of 10000\n",
      "Processed 2550 of 10000\n",
      "Processed 2600 of 10000\n",
      "Processed 2650 of 10000\n",
      "Processed 2700 of 10000\n",
      "Processed 2750 of 10000\n",
      "Processed 2800 of 10000\n",
      "Processed 2850 of 10000\n",
      "Processed 2900 of 10000\n",
      "Processed 2950 of 10000\n",
      "Processed 3000 of 10000\n",
      "Processed 3050 of 10000\n",
      "Processed 3100 of 10000\n",
      "Processed 3150 of 10000\n",
      "Processed 3200 of 10000\n",
      "Processed 3250 of 10000\n",
      "Processed 3300 of 10000\n",
      "Processed 3350 of 10000\n",
      "Processed 3400 of 10000\n",
      "Processed 3450 of 10000\n",
      "Processed 3500 of 10000\n",
      "Processed 3550 of 10000\n",
      "Processed 3600 of 10000\n",
      "Processed 3650 of 10000\n",
      "Processed 3700 of 10000\n",
      "Processed 3750 of 10000\n",
      "Processed 3800 of 10000\n",
      "Processed 3850 of 10000\n",
      "Processed 3900 of 10000\n",
      "Processed 3950 of 10000\n",
      "Processed 4000 of 10000\n",
      "Processed 4050 of 10000\n",
      "Processed 4100 of 10000\n",
      "Processed 4150 of 10000\n",
      "Processed 4200 of 10000\n",
      "Processed 4250 of 10000\n",
      "Processed 4300 of 10000\n",
      "Processed 4350 of 10000\n",
      "Processed 4400 of 10000\n",
      "Processed 4450 of 10000\n",
      "Processed 4500 of 10000\n",
      "Processed 4550 of 10000\n",
      "Processed 4600 of 10000\n",
      "Processed 4650 of 10000\n",
      "Processed 4700 of 10000\n",
      "Processed 4750 of 10000\n",
      "Processed 4800 of 10000\n",
      "Processed 4850 of 10000\n",
      "Processed 4900 of 10000\n",
      "Processed 4950 of 10000\n",
      "Processed 5000 of 10000\n",
      "Processed 5050 of 10000\n",
      "Processed 5100 of 10000\n",
      "Processed 5150 of 10000\n",
      "Processed 5200 of 10000\n",
      "Processed 5250 of 10000\n",
      "Processed 5300 of 10000\n",
      "Processed 5350 of 10000\n",
      "Processed 5400 of 10000\n",
      "Processed 5450 of 10000\n",
      "Processed 5500 of 10000\n",
      "Processed 5550 of 10000\n",
      "Processed 5600 of 10000\n",
      "Processed 5650 of 10000\n",
      "Processed 5700 of 10000\n",
      "Processed 5750 of 10000\n",
      "Processed 5800 of 10000\n",
      "Processed 5850 of 10000\n",
      "Processed 5900 of 10000\n",
      "Processed 5950 of 10000\n",
      "Processed 6000 of 10000\n",
      "Processed 6050 of 10000\n",
      "Processed 6100 of 10000\n",
      "Processed 6150 of 10000\n",
      "Processed 6200 of 10000\n",
      "Processed 6250 of 10000\n",
      "Processed 6300 of 10000\n",
      "Processed 6350 of 10000\n",
      "Processed 6400 of 10000\n",
      "Processed 6450 of 10000\n",
      "Processed 6500 of 10000\n",
      "Processed 6550 of 10000\n",
      "Processed 6600 of 10000\n",
      "Processed 6650 of 10000\n",
      "Processed 6700 of 10000\n",
      "Processed 6750 of 10000\n",
      "Processed 6800 of 10000\n",
      "Processed 6850 of 10000\n",
      "Processed 6900 of 10000\n",
      "Processed 6950 of 10000\n",
      "Processed 7000 of 10000\n",
      "Processed 7050 of 10000\n",
      "Processed 7100 of 10000\n",
      "Processed 7150 of 10000\n",
      "Processed 7200 of 10000\n",
      "Processed 7250 of 10000\n",
      "Processed 7300 of 10000\n",
      "Processed 7350 of 10000\n",
      "Processed 7400 of 10000\n",
      "Processed 7450 of 10000\n",
      "Processed 7500 of 10000\n",
      "Processed 7550 of 10000\n",
      "Processed 7600 of 10000\n",
      "Processed 7650 of 10000\n",
      "Processed 7700 of 10000\n",
      "Processed 7750 of 10000\n",
      "Processed 7800 of 10000\n",
      "Processed 7850 of 10000\n",
      "Processed 7900 of 10000\n",
      "Processed 7950 of 10000\n",
      "Processed 8000 of 10000\n",
      "Processed 8050 of 10000\n",
      "Processed 8100 of 10000\n",
      "Processed 8150 of 10000\n",
      "Processed 8200 of 10000\n",
      "Processed 8250 of 10000\n",
      "Processed 8300 of 10000\n",
      "Processed 8350 of 10000\n",
      "Processed 8400 of 10000\n",
      "Processed 8450 of 10000\n",
      "Processed 8500 of 10000\n",
      "Processed 8550 of 10000\n",
      "Processed 8600 of 10000\n",
      "Processed 8650 of 10000\n",
      "Processed 8700 of 10000\n",
      "Processed 8750 of 10000\n",
      "Processed 8800 of 10000\n",
      "Processed 8850 of 10000\n",
      "Processed 8900 of 10000\n",
      "Processed 8950 of 10000\n",
      "Processed 9000 of 10000\n",
      "Processed 9050 of 10000\n",
      "Processed 9100 of 10000\n",
      "Processed 9150 of 10000\n",
      "Processed 9200 of 10000\n",
      "Processed 9250 of 10000\n",
      "Processed 9300 of 10000\n",
      "Processed 9350 of 10000\n",
      "Processed 9400 of 10000\n",
      "Processed 9450 of 10000\n",
      "Processed 9500 of 10000\n",
      "Processed 9550 of 10000\n",
      "Processed 9600 of 10000\n",
      "Processed 9650 of 10000\n",
      "Processed 9700 of 10000\n",
      "Processed 9750 of 10000\n",
      "Processed 9800 of 10000\n",
      "Processed 9850 of 10000\n",
      "Processed 9900 of 10000\n",
      "Processed 9950 of 10000\n"
     ]
    }
   ],
   "source": [
    "images = prep_data(image_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for AffectNet\n",
    "labels = training_csv['expression'][:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean        4.048000\n",
       "std         3.983411\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         2.000000\n",
       "75%         8.000000\n",
       "max        10.000000\n",
       "Name: expression, dtype: float64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For jaffe\n",
    "image_labels = np.array([title[3:5] for title in image_title])\n",
    "labels = []\n",
    "for i, label in enumerate(image_labels):\n",
    "    if label == 'AN':\n",
    "        labels.append(0)\n",
    "    if label == 'DI':\n",
    "        labels.append(1)\n",
    "    if label == 'FE':\n",
    "        labels.append(2)\n",
    "    if label == 'SU':\n",
    "        labels.append(3)\n",
    "    if label == 'SA':\n",
    "        labels.append(4)\n",
    "    if label == 'HA':\n",
    "        labels.append(5)\n",
    "    if label == 'NE':\n",
    "        labels.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.20, random_state=69)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], H, W, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], H, W, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = CNN_EXP(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_45 (Conv2D)           (None, 126, 126, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 124, 124, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 41, 41, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 39, 39, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               2769024   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 11)                1419      \n",
      "=================================================================\n",
      "Total params: 2,863,115\n",
      "Trainable params: 2,863,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      " - 20s - loss: 2.0183 - acc: 0.2969 - val_loss: 1.8771 - val_acc: 0.3505\n",
      "Epoch 2/5\n",
      " - 20s - loss: 1.9596 - acc: 0.3153 - val_loss: 1.8745 - val_acc: 0.3490\n",
      "Epoch 3/5\n",
      " - 20s - loss: 1.9494 - acc: 0.3178 - val_loss: 1.8787 - val_acc: 0.3520\n",
      "Epoch 4/5\n",
      " - 20s - loss: 1.9463 - acc: 0.3198 - val_loss: 1.8764 - val_acc: 0.3530\n",
      "Epoch 5/5\n",
      " - 20s - loss: 1.9412 - acc: 0.3206 - val_loss: 1.8714 - val_acc: 0.3520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d501179080>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5,batch_size=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Error: 64.80%\n"
     ]
    }
   ],
   "source": [
    "scores = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Classification Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
