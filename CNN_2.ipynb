{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kodingan ini hanya memanfaatkan image Part 1-2 dari situs AffectNet\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_root = 'training_fixed.csv'\n",
    "image_root = 'Affectnet/Manually_Annotated_Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(label_root)\n",
    "image_dirs = [image_root + '/' + dir_ for dir_ in label_df['subDirectory_filePath'].tolist()]\n",
    "labels = [x for x in label_df['expression'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 image(s) have been read\n",
      "100 image(s) have been read\n",
      "150 image(s) have been read\n",
      "200 image(s) have been read\n",
      "250 image(s) have been read\n",
      "300 image(s) have been read\n",
      "350 image(s) have been read\n",
      "400 image(s) have been read\n",
      "450 image(s) have been read\n",
      "500 image(s) have been read\n",
      "550 image(s) have been read\n",
      "600 image(s) have been read\n",
      "650 image(s) have been read\n",
      "700 image(s) have been read\n",
      "750 image(s) have been read\n",
      "800 image(s) have been read\n",
      "850 image(s) have been read\n",
      "900 image(s) have been read\n",
      "950 image(s) have been read\n",
      "1000 image(s) have been read\n",
      "1050 image(s) have been read\n",
      "1100 image(s) have been read\n",
      "1150 image(s) have been read\n",
      "1200 image(s) have been read\n",
      "1250 image(s) have been read\n",
      "1300 image(s) have been read\n",
      "1350 image(s) have been read\n",
      "1400 image(s) have been read\n",
      "1450 image(s) have been read\n",
      "1500 image(s) have been read\n",
      "1550 image(s) have been read\n",
      "1600 image(s) have been read\n",
      "1650 image(s) have been read\n",
      "1700 image(s) have been read\n",
      "1750 image(s) have been read\n",
      "1800 image(s) have been read\n",
      "1850 image(s) have been read\n",
      "1900 image(s) have been read\n",
      "1950 image(s) have been read\n",
      "2000 image(s) have been read\n",
      "2050 image(s) have been read\n",
      "2100 image(s) have been read\n",
      "2150 image(s) have been read\n",
      "2200 image(s) have been read\n",
      "2250 image(s) have been read\n",
      "2300 image(s) have been read\n",
      "2350 image(s) have been read\n",
      "2400 image(s) have been read\n",
      "2450 image(s) have been read\n",
      "2500 image(s) have been read\n",
      "2550 image(s) have been read\n",
      "2600 image(s) have been read\n",
      "2650 image(s) have been read\n",
      "2700 image(s) have been read\n",
      "2750 image(s) have been read\n",
      "2800 image(s) have been read\n",
      "2850 image(s) have been read\n",
      "2900 image(s) have been read\n",
      "2950 image(s) have been read\n",
      "3000 image(s) have been read\n",
      "3050 image(s) have been read\n",
      "3100 image(s) have been read\n",
      "3150 image(s) have been read\n",
      "3200 image(s) have been read\n",
      "3250 image(s) have been read\n",
      "3300 image(s) have been read\n",
      "3350 image(s) have been read\n",
      "3400 image(s) have been read\n",
      "3450 image(s) have been read\n",
      "3500 image(s) have been read\n",
      "3550 image(s) have been read\n",
      "3600 image(s) have been read\n",
      "3650 image(s) have been read\n",
      "3700 image(s) have been read\n",
      "3750 image(s) have been read\n",
      "3800 image(s) have been read\n",
      "3850 image(s) have been read\n",
      "3900 image(s) have been read\n",
      "3950 image(s) have been read\n",
      "4000 image(s) have been read\n",
      "4050 image(s) have been read\n",
      "4100 image(s) have been read\n",
      "4150 image(s) have been read\n",
      "4200 image(s) have been read\n",
      "4250 image(s) have been read\n",
      "4300 image(s) have been read\n",
      "4350 image(s) have been read\n",
      "4400 image(s) have been read\n",
      "4450 image(s) have been read\n",
      "4500 image(s) have been read\n",
      "4550 image(s) have been read\n",
      "4600 image(s) have been read\n",
      "4650 image(s) have been read\n",
      "4700 image(s) have been read\n",
      "4750 image(s) have been read\n",
      "4800 image(s) have been read\n",
      "4850 image(s) have been read\n",
      "4900 image(s) have been read\n",
      "4950 image(s) have been read\n",
      "5000 image(s) have been read\n",
      "5050 image(s) have been read\n",
      "5100 image(s) have been read\n",
      "5150 image(s) have been read\n",
      "5200 image(s) have been read\n",
      "5250 image(s) have been read\n",
      "5300 image(s) have been read\n",
      "5350 image(s) have been read\n",
      "5400 image(s) have been read\n",
      "5450 image(s) have been read\n",
      "5500 image(s) have been read\n",
      "5550 image(s) have been read\n",
      "5600 image(s) have been read\n",
      "5650 image(s) have been read\n",
      "5700 image(s) have been read\n",
      "5750 image(s) have been read\n",
      "5800 image(s) have been read\n",
      "5850 image(s) have been read\n",
      "5900 image(s) have been read\n",
      "5950 image(s) have been read\n",
      "6000 image(s) have been read\n",
      "6050 image(s) have been read\n",
      "6100 image(s) have been read\n",
      "6150 image(s) have been read\n",
      "6200 image(s) have been read\n",
      "6250 image(s) have been read\n",
      "6300 image(s) have been read\n",
      "6350 image(s) have been read\n",
      "6400 image(s) have been read\n",
      "6450 image(s) have been read\n",
      "6500 image(s) have been read\n",
      "6550 image(s) have been read\n",
      "6600 image(s) have been read\n",
      "6650 image(s) have been read\n",
      "6700 image(s) have been read\n",
      "6750 image(s) have been read\n",
      "6800 image(s) have been read\n",
      "6850 image(s) have been read\n",
      "6900 image(s) have been read\n",
      "6950 image(s) have been read\n",
      "7000 image(s) have been read\n",
      "7050 image(s) have been read\n",
      "7100 image(s) have been read\n",
      "7150 image(s) have been read\n",
      "7200 image(s) have been read\n",
      "7250 image(s) have been read\n",
      "7300 image(s) have been read\n",
      "7350 image(s) have been read\n",
      "7400 image(s) have been read\n",
      "7450 image(s) have been read\n",
      "7500 image(s) have been read\n",
      "7550 image(s) have been read\n",
      "7600 image(s) have been read\n",
      "7650 image(s) have been read\n",
      "7700 image(s) have been read\n",
      "7750 image(s) have been read\n",
      "7800 image(s) have been read\n",
      "7850 image(s) have been read\n",
      "7900 image(s) have been read\n",
      "7950 image(s) have been read\n",
      "8000 image(s) have been read\n",
      "8050 image(s) have been read\n",
      "8100 image(s) have been read\n",
      "8150 image(s) have been read\n",
      "8200 image(s) have been read\n",
      "8250 image(s) have been read\n",
      "8300 image(s) have been read\n",
      "8350 image(s) have been read\n",
      "8400 image(s) have been read\n",
      "8450 image(s) have been read\n",
      "8500 image(s) have been read\n",
      "8550 image(s) have been read\n",
      "8600 image(s) have been read\n",
      "8650 image(s) have been read\n",
      "8700 image(s) have been read\n",
      "8750 image(s) have been read\n",
      "8800 image(s) have been read\n",
      "8850 image(s) have been read\n",
      "8900 image(s) have been read\n",
      "8950 image(s) have been read\n",
      "9000 image(s) have been read\n",
      "9050 image(s) have been read\n",
      "9100 image(s) have been read\n",
      "9150 image(s) have been read\n",
      "9200 image(s) have been read\n",
      "9250 image(s) have been read\n",
      "9300 image(s) have been read\n",
      "9350 image(s) have been read\n",
      "9400 image(s) have been read\n",
      "9450 image(s) have been read\n",
      "9500 image(s) have been read\n",
      "9550 image(s) have been read\n",
      "9600 image(s) have been read\n",
      "9650 image(s) have been read\n",
      "9700 image(s) have been read\n",
      "9750 image(s) have been read\n",
      "9800 image(s) have been read\n",
      "9850 image(s) have been read\n",
      "9900 image(s) have been read\n",
      "9950 image(s) have been read\n",
      "10000 image(s) have been read\n"
     ]
    }
   ],
   "source": [
    "H = 128\n",
    "W = 128\n",
    "def read_image(file_path):\n",
    "    global H,W\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    dimension = (H,W)\n",
    "    resized = cv2.resize(img, dimension)\n",
    "    return resized\n",
    "def prep_data(images):\n",
    "    global H,W\n",
    "    label = []\n",
    "    data = np.ndarray((10000, 1, H, W), dtype=np.uint8)\n",
    "    i = 0\n",
    "    for image_file in images:\n",
    "        if(i == 10000):\n",
    "            break\n",
    "        try:\n",
    "            image = read_image(image_file)\n",
    "        except:\n",
    "            continue\n",
    "        data[i] = image\n",
    "        label.append(labels[i])\n",
    "        i += 1\n",
    "        if i%50 == 0: print('{} image(s) have been read'.format(i))\n",
    "    return data, np.array(label)\n",
    "images_fix, labels_fix = prep_data(image_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(images_fix, labels_fix, test_size=0.20, random_state=69)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], H, W, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], H, W, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(conv1_units, conv2_units, kernel_size, pool_size, dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(conv1_units, kernel_size=(kernel_size, kernel_size),\n",
    "                     activation='relu',\n",
    "                     input_shape=(128,128,1)))\n",
    "    model.add(Conv2D(conv2_units, (kernel_size, kernel_size), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(pool_size,pool_size)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(2*dropout_rate))\n",
    "    model.add(Dense(11, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='Adadelta',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = CNN(48,56,3,4,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      " - 853s - loss: 11.0815 - acc: 0.3121 - val_loss: 10.5412 - val_acc: 0.3460\n",
      "Epoch 2/10\n"
     ]
    }
   ],
   "source": [
    "model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10,batch_size=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6",
   "language": "python",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
