{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = [\"https://towardsdatascience.com/build-your-own-convolution-neural-network-in-5-mins-4217c2cf964f\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAFFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 128\n",
    "W = 128\n",
    "def read_image(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    dimension = (H,W)\n",
    "    resized = cv2.resize(img, dimension)\n",
    "    return resized\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, 1, H, W), dtype=np.uint8)\n",
    "    for i, image_file in enumerate(images):\n",
    "        image = read_image(image_file)\n",
    "        data[i] = image\n",
    "        if i%50 == 0: print('Processed {} of {}'.format(i, count))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hafizh\\Documents\\1-ML\\Proyek Akhir\\Making-Learning\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\Hafizh\\Documents\\1-ML\\Proyek Akhir\\Making-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root = 'dataset/jaffe/'\n",
    "image_dirs = [image_root + x for x in os.listdir(image_root)]\n",
    "try:\n",
    "    image_dirs.remove('dataset/jaffe/.ipynb_checkpoints')\n",
    "    image_dirs.remove('dataset/jaffe/Untitled.ipynb')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 213\n",
      "Processed 50 of 213\n",
      "Processed 100 of 213\n",
      "Processed 150 of 213\n",
      "Processed 200 of 213\n"
     ]
    }
   ],
   "source": [
    "images = prep_data(image_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_labels = np.array([title[3:5] for title in image_title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i, label in enumerate(image_labels):\n",
    "    if label == 'AN':\n",
    "        labels.append(0)\n",
    "    if label == 'DI':\n",
    "        labels.append(1)\n",
    "    if label == 'FE':\n",
    "        labels.append(2)\n",
    "    if label == 'SU':\n",
    "        labels.append(3)\n",
    "    if label == 'SA':\n",
    "        labels.append(4)\n",
    "    if label == 'HA':\n",
    "        labels.append(5)\n",
    "    if label == 'NE':\n",
    "        labels.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.20, random_state=69)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], H, W, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], H, W, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AffectNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hafizh\\Documents\\1-ML\\Proyek Akhir\\Making-Learning\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\Hafizh\\Documents\\1-ML\\Proyek Akhir\\Making-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv = pd.read_csv('dataset/training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_csv = pd.read_csv('dataset/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\\n"
     ]
    }
   ],
   "source": [
    "cd E:\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root = 'Manually_Annotated_Images/'\n",
    "image_dirs1 = []\n",
    "label = training_csv['expression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10000\n",
    "i = 0\n",
    "for i in range(size):\n",
    "    path = image_root + training_csv['subDirectory_filePath'][i]\n",
    "    image_dirs1.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 256\n",
    "W = 256\n",
    "C = 1\n",
    "def read_image1(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    dimension = (H,W)\n",
    "    resized = cv2.resize(img, dimension)\n",
    "    return resized\n",
    "def prep_data1(images):\n",
    "    count = len(images)\n",
    "    labels = []\n",
    "    data = np.ndarray((count, C, H, W), dtype=np.uint8)\n",
    "    for i, image_file1 in enumerate(images):\n",
    "        image = read_image(image_file1)\n",
    "        data[i] = image\n",
    "        if i%500 == 0: print('Processed {} of {}'.format(i, count))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-510668e58854>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimages_affectnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_data1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_dirs1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-145-7ec29d8dddfc>\u001b[0m in \u001b[0;36mprep_data1\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_file1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_file1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "images_affectnet = prep_data1(image_dirs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 1, 256, 256), dtype=uint8)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_affectnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data = np.ndarray((10000, H, W, 1), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN1(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=(H,W,1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='Adadelta',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Hafizh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Hafizh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "cnn_model = CNN1(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 126, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 124, 124, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 246016)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               31490176  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 31,509,895\n",
      "Trainable params: 31,509,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples, validate on 43 samples\n",
      "Epoch 1/30\n",
      " - 54s - loss: 13.8299 - acc: 0.1412 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 2/30\n",
      " - 17s - loss: 13.6530 - acc: 0.1529 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 3/30\n",
      " - 16s - loss: 13.7478 - acc: 0.1471 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 4/30\n",
      " - 16s - loss: 13.8426 - acc: 0.1412 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 5/30\n",
      " - 16s - loss: 13.7478 - acc: 0.1471 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 6/30\n",
      " - 16s - loss: 13.4634 - acc: 0.1647 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 7/30\n",
      " - 16s - loss: 13.7478 - acc: 0.1471 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 8/30\n",
      " - 16s - loss: 13.5582 - acc: 0.1588 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 9/30\n",
      " - 16s - loss: 13.7478 - acc: 0.1471 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 10/30\n",
      " - 16s - loss: 13.5582 - acc: 0.1588 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 11/30\n",
      " - 16s - loss: 13.6530 - acc: 0.1529 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 12/30\n",
      " - 16s - loss: 13.7478 - acc: 0.1471 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 13/30\n",
      " - 16s - loss: 13.5582 - acc: 0.1588 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 14/30\n",
      " - 16s - loss: 13.5582 - acc: 0.1588 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 15/30\n",
      " - 16s - loss: 13.4634 - acc: 0.1647 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 16/30\n",
      " - 16s - loss: 13.5582 - acc: 0.1588 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 17/30\n",
      " - 16s - loss: 13.4634 - acc: 0.1647 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 18/30\n",
      " - 16s - loss: 13.5582 - acc: 0.1588 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 19/30\n",
      " - 17s - loss: 13.5582 - acc: 0.1588 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 20/30\n",
      " - 16s - loss: 13.4634 - acc: 0.1647 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 21/30\n",
      " - 16s - loss: 14.6503 - acc: 0.0882 - val_loss: 12.3697 - val_acc: 0.2326\n",
      "Epoch 22/30\n",
      " - 16s - loss: 13.2737 - acc: 0.1765 - val_loss: 12.3697 - val_acc: 0.2326\n",
      "Epoch 23/30\n",
      " - 16s - loss: 14.0322 - acc: 0.1294 - val_loss: 12.3697 - val_acc: 0.2326\n",
      "Epoch 24/30\n",
      " - 16s - loss: 13.9374 - acc: 0.1353 - val_loss: 12.3697 - val_acc: 0.2326\n",
      "Epoch 25/30\n",
      " - 16s - loss: 13.4634 - acc: 0.1647 - val_loss: 12.3697 - val_acc: 0.2326\n",
      "Epoch 26/30\n",
      " - 16s - loss: 14.1270 - acc: 0.1235 - val_loss: 12.3697 - val_acc: 0.2326\n",
      "Epoch 27/30\n",
      " - 16s - loss: 14.5063 - acc: 0.1000 - val_loss: 12.3697 - val_acc: 0.2326\n",
      "Epoch 28/30\n",
      " - 16s - loss: 14.2218 - acc: 0.1176 - val_loss: 12.3697 - val_acc: 0.2326\n",
      "Epoch 29/30\n",
      " - 16s - loss: 13.8426 - acc: 0.1412 - val_loss: 12.3697 - val_acc: 0.2326\n",
      "Epoch 30/30\n",
      " - 16s - loss: 14.4115 - acc: 0.1059 - val_loss: 12.3697 - val_acc: 0.2326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aff8aad048>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30,batch_size=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Error: 76.74%\n"
     ]
    }
   ],
   "source": [
    "scores = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Classification Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AffectNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN2(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=(H,W,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AveragePooling2D())\n",
    "    model.add(Conv2D(64, kernel_size=(5, 5), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='Adadelta',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model2 = CNN2(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 124, 124, 32)      832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 124, 124, 32)      128       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 58, 58, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 58, 58, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 27, 27, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 27, 27, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               2769152   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 2,892,615\n",
      "Trainable params: 2,892,295\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples, validate on 43 samples\n",
      "Epoch 1/30\n",
      " - 15s - loss: 11.3594 - acc: 0.1412 - val_loss: 12.2967 - val_acc: 0.0930\n",
      "Epoch 2/30\n",
      " - 13s - loss: 12.6103 - acc: 0.0882 - val_loss: 12.6015 - val_acc: 0.0930\n",
      "Epoch 3/30\n",
      " - 12s - loss: 12.3959 - acc: 0.1588 - val_loss: 14.1827 - val_acc: 0.0930\n",
      "Epoch 4/30\n",
      " - 12s - loss: 11.5361 - acc: 0.1765 - val_loss: 13.0276 - val_acc: 0.1395\n",
      "Epoch 5/30\n",
      " - 12s - loss: 11.7554 - acc: 0.0941 - val_loss: 7.9040 - val_acc: 0.1163\n",
      "Epoch 6/30\n",
      " - 13s - loss: 11.4936 - acc: 0.1235 - val_loss: 10.7497 - val_acc: 0.0698\n",
      "Epoch 7/30\n",
      " - 12s - loss: 10.1768 - acc: 0.1412 - val_loss: 7.9333 - val_acc: 0.0698\n",
      "Epoch 8/30\n",
      " - 13s - loss: 8.7488 - acc: 0.1176 - val_loss: 8.6283 - val_acc: 0.1163\n",
      "Epoch 9/30\n",
      " - 12s - loss: 6.5072 - acc: 0.1588 - val_loss: 3.5355 - val_acc: 0.1628\n",
      "Epoch 10/30\n",
      " - 12s - loss: 4.3396 - acc: 0.2176 - val_loss: 3.3138 - val_acc: 0.1860\n",
      "Epoch 11/30\n",
      " - 13s - loss: 3.2349 - acc: 0.1588 - val_loss: 2.0685 - val_acc: 0.1163\n",
      "Epoch 12/30\n",
      " - 13s - loss: 2.1002 - acc: 0.1529 - val_loss: 1.9625 - val_acc: 0.1395\n",
      "Epoch 13/30\n",
      " - 13s - loss: 2.2821 - acc: 0.1353 - val_loss: 1.9443 - val_acc: 0.1395\n",
      "Epoch 14/30\n",
      " - 13s - loss: 2.0934 - acc: 0.1353 - val_loss: 1.9835 - val_acc: 0.0698\n",
      "Epoch 15/30\n",
      " - 12s - loss: 2.0485 - acc: 0.1588 - val_loss: 1.9514 - val_acc: 0.0930\n",
      "Epoch 16/30\n",
      " - 12s - loss: 1.9710 - acc: 0.1353 - val_loss: 1.9737 - val_acc: 0.1163\n",
      "Epoch 17/30\n",
      " - 13s - loss: 1.9532 - acc: 0.1647 - val_loss: 1.9289 - val_acc: 0.0930\n",
      "Epoch 18/30\n",
      " - 13s - loss: 1.9764 - acc: 0.1824 - val_loss: 2.0570 - val_acc: 0.1163\n",
      "Epoch 19/30\n",
      " - 12s - loss: 1.9527 - acc: 0.2059 - val_loss: 1.9344 - val_acc: 0.1628\n",
      "Epoch 20/30\n",
      " - 13s - loss: 1.9009 - acc: 0.2000 - val_loss: 1.9718 - val_acc: 0.1163\n",
      "Epoch 21/30\n",
      " - 12s - loss: 1.9119 - acc: 0.2059 - val_loss: 1.9459 - val_acc: 0.0930\n",
      "Epoch 22/30\n",
      " - 12s - loss: 2.1596 - acc: 0.2294 - val_loss: 1.8881 - val_acc: 0.1860\n",
      "Epoch 23/30\n",
      " - 12s - loss: 1.9322 - acc: 0.2059 - val_loss: 1.9273 - val_acc: 0.1395\n",
      "Epoch 24/30\n",
      " - 13s - loss: 2.0155 - acc: 0.2294 - val_loss: 1.9419 - val_acc: 0.0930\n",
      "Epoch 25/30\n",
      " - 13s - loss: 1.9482 - acc: 0.1765 - val_loss: 1.9588 - val_acc: 0.0930\n",
      "Epoch 26/30\n",
      " - 13s - loss: 2.0736 - acc: 0.2471 - val_loss: 1.7947 - val_acc: 0.2093\n",
      "Epoch 27/30\n",
      " - 13s - loss: 1.8205 - acc: 0.2412 - val_loss: 1.7611 - val_acc: 0.1860\n",
      "Epoch 28/30\n",
      " - 13s - loss: 1.8161 - acc: 0.2176 - val_loss: 1.7447 - val_acc: 0.2093\n",
      "Epoch 29/30\n",
      " - 13s - loss: 1.7427 - acc: 0.2412 - val_loss: 1.6839 - val_acc: 0.2558\n",
      "Epoch 30/30\n",
      " - 13s - loss: 1.7808 - acc: 0.2412 - val_loss: 1.6768 - val_acc: 0.2558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1afe7ecfac8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30,batch_size=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Error: 74.42%\n"
     ]
    }
   ],
   "source": [
    "scores = cnn_model2.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Classification Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN3(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(W, H, 1)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(2*32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2*32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(2*2*32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2*2*32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(2*2*2*32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2*2*2*32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(2*2*2*32, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2*2*32, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2*32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 126, 126, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 126, 126, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 126, 126, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 63, 63, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 63, 63, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 63, 63, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 63, 63, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 31, 31, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 31, 31, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 31, 31, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 31, 31, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 15, 15, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 15, 15, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 15, 15, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               3211520   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 4,428,519\n",
      "Trainable params: 4,426,663\n",
      "Non-trainable params: 1,856\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def CNN3(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(W, H, 1)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(2*32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2*32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(2*2*32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2*2*32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(2*2*2*32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2*2*2*32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(2*2*2*32, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2*2*32, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(2*32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples, validate on 43 samples\n",
      "Epoch 1/30\n",
      " - 21s - loss: 3.4499 - acc: 0.1294 - val_loss: 2.2324 - val_acc: 0.1395\n",
      "Epoch 2/30\n",
      " - 20s - loss: 2.5230 - acc: 0.1412 - val_loss: 2.0269 - val_acc: 0.1860\n",
      "Epoch 3/30\n",
      " - 20s - loss: 2.2820 - acc: 0.1529 - val_loss: 1.9728 - val_acc: 0.1860\n",
      "Epoch 4/30\n",
      " - 21s - loss: 1.9957 - acc: 0.1353 - val_loss: 1.9618 - val_acc: 0.1395\n",
      "Epoch 5/30\n",
      " - 22s - loss: 1.9480 - acc: 0.1353 - val_loss: 1.9678 - val_acc: 0.1163\n",
      "Epoch 6/30\n",
      " - 20s - loss: 1.9606 - acc: 0.1353 - val_loss: 1.9570 - val_acc: 0.1860\n",
      "Epoch 7/30\n",
      " - 21s - loss: 1.9341 - acc: 0.1529 - val_loss: 1.9522 - val_acc: 0.2326\n",
      "Epoch 8/30\n",
      " - 22s - loss: 2.0207 - acc: 0.1765 - val_loss: 1.9653 - val_acc: 0.1628\n",
      "Epoch 9/30\n",
      " - 21s - loss: 1.9346 - acc: 0.1647 - val_loss: 1.9722 - val_acc: 0.1628\n",
      "Epoch 10/30\n",
      " - 22s - loss: 1.9531 - acc: 0.1529 - val_loss: 1.9484 - val_acc: 0.0465\n",
      "Epoch 11/30\n",
      " - 22s - loss: 1.9637 - acc: 0.1647 - val_loss: 1.9463 - val_acc: 0.0930\n",
      "Epoch 12/30\n",
      " - 22s - loss: 1.9414 - acc: 0.1588 - val_loss: 1.9509 - val_acc: 0.0930\n",
      "Epoch 13/30\n",
      " - 22s - loss: 1.9428 - acc: 0.1588 - val_loss: 1.9582 - val_acc: 0.0930\n",
      "Epoch 14/30\n",
      " - 23s - loss: 1.9389 - acc: 0.1647 - val_loss: 1.9580 - val_acc: 0.0930\n",
      "Epoch 15/30\n",
      " - 23s - loss: 1.9409 - acc: 0.1588 - val_loss: 1.9554 - val_acc: 0.0930\n",
      "Epoch 16/30\n",
      " - 22s - loss: 1.9589 - acc: 0.1588 - val_loss: 1.9593 - val_acc: 0.0930\n",
      "Epoch 17/30\n",
      " - 21s - loss: 1.9439 - acc: 0.1588 - val_loss: 1.9595 - val_acc: 0.0930\n",
      "Epoch 18/30\n",
      " - 22s - loss: 1.9428 - acc: 0.1588 - val_loss: 1.9592 - val_acc: 0.0930\n",
      "Epoch 19/30\n",
      " - 22s - loss: 1.9379 - acc: 0.1647 - val_loss: 1.9539 - val_acc: 0.1395\n",
      "Epoch 20/30\n",
      " - 22s - loss: 1.9425 - acc: 0.1647 - val_loss: 1.9611 - val_acc: 0.0698\n",
      "Epoch 21/30\n",
      " - 23s - loss: 1.9398 - acc: 0.1647 - val_loss: 1.9596 - val_acc: 0.0930\n",
      "Epoch 22/30\n",
      " - 21s - loss: 1.9442 - acc: 0.1588 - val_loss: 1.9596 - val_acc: 0.0930\n",
      "Epoch 23/30\n",
      " - 21s - loss: 1.9398 - acc: 0.1647 - val_loss: 1.9606 - val_acc: 0.0930\n",
      "Epoch 24/30\n",
      " - 21s - loss: 1.9317 - acc: 0.1647 - val_loss: 1.9608 - val_acc: 0.0930\n",
      "Epoch 25/30\n",
      " - 22s - loss: 1.9523 - acc: 0.1647 - val_loss: 1.9613 - val_acc: 0.0930\n",
      "Epoch 26/30\n",
      " - 21s - loss: 1.9429 - acc: 0.1647 - val_loss: 1.9631 - val_acc: 0.0930\n",
      "Epoch 27/30\n",
      " - 22s - loss: 1.9249 - acc: 0.1647 - val_loss: 1.9641 - val_acc: 0.0930\n",
      "Epoch 28/30\n",
      " - 22s - loss: 1.9222 - acc: 0.1647 - val_loss: 1.9631 - val_acc: 0.0930\n",
      "Epoch 29/30\n",
      " - 21s - loss: 1.9784 - acc: 0.1588 - val_loss: 1.9629 - val_acc: 0.0930\n",
      "Epoch 30/30\n",
      " - 20s - loss: 1.9426 - acc: 0.1588 - val_loss: 1.9634 - val_acc: 0.0930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1afcfb83668>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30,batch_size=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Error: 90.70%\n"
     ]
    }
   ],
   "source": [
    "scores = cnn_model3.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Classification Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 (CNN3 yang ditulis pada laporan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN4(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(48, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=(H,W,1)))\n",
    "    model.add(Conv2D(56, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='Adadelta',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 126, 126, 48)      480       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 124, 124, 56)      24248     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 31, 31, 56)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 53816)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               6888576   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 6,922,015\n",
      "Trainable params: 6,922,015\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn4 = CNN4(7)\n",
    "model_cnn4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples, validate on 43 samples\n",
      "Epoch 1/15\n",
      " - 24s - loss: 13.6532 - acc: 0.1529 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 2/15\n",
      " - 10s - loss: 14.2003 - acc: 0.1176 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 3/15\n",
      " - 10s - loss: 13.5776 - acc: 0.1529 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 4/15\n",
      " - 10s - loss: 14.2218 - acc: 0.1176 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 5/15\n",
      " - 10s - loss: 13.7478 - acc: 0.1471 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 6/15\n",
      " - 10s - loss: 13.4634 - acc: 0.1647 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 7/15\n",
      " - 11s - loss: 12.9113 - acc: 0.1941 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 8/15\n",
      " - 10s - loss: 13.2737 - acc: 0.1765 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 9/15\n",
      " - 10s - loss: 13.3686 - acc: 0.1706 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 10/15\n",
      " - 10s - loss: 13.6530 - acc: 0.1529 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 11/15\n",
      " - 12s - loss: 13.5582 - acc: 0.1588 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 12/15\n",
      " - 11s - loss: 13.5180 - acc: 0.1588 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 13/15\n",
      " - 10s - loss: 13.9374 - acc: 0.1353 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 14/15\n",
      " - 11s - loss: 13.8724 - acc: 0.1353 - val_loss: 14.6187 - val_acc: 0.0930\n",
      "Epoch 15/15\n",
      " - 11s - loss: 13.7478 - acc: 0.1471 - val_loss: 14.6187 - val_acc: 0.0930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b0de768358>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn4.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15,batch_size=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Error: 90.70%\n"
     ]
    }
   ],
   "source": [
    "scores = model_cnn4.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Classification Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
